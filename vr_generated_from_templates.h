//Generated by './generateBackendInterOperator.py'
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verroucast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
#ifdef USE_VERROU_QUAD
// generation of operation cast backend mcaquad


static VG_REGPARM(3) Int vr_mcaquadcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_mcaquad_cast_double_to_float(*arg1, &res,backend_mcaquad_context);
  Int *d = (Int*)(&res);
  return *d;
}
#endif //USE_VERROU_QUAD
// generation of operation cast backend checkdenorm


static VG_REGPARM(3) Int vr_checkdenormcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_checkdenorm_cast_double_to_float(*arg1, &res,backend_checkdenorm_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verroucheck_float_maxcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float(*arg1, &res,backend_verrou_context);
  interflop_check_float_max_cast_double_to_float(*arg1, &res,backend_check_float_max_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_NEARESTcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_NEAREST(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_UPWARDcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_UPWARD(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_DOWNWARDcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_DOWNWARD(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_FARTHESTcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_FARTHEST(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_ZEROcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_ZERO(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_AWAY_ZEROcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_AWAY_ZERO(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_RANDOMcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_RANDOM(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_RANDOM_DETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_RANDOM_DET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_RANDOM_COMDETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_RANDOM_COMDET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_AVERAGEcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_AVERAGE(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_AVERAGE_DETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_AVERAGE_DET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_AVERAGE_COMDETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_AVERAGE_COMDET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_PRANDOMcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_PRANDOM(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_PRANDOM_DETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_PRANDOM_DET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_PRANDOM_COMDETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_PRANDOM_COMDET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_RANDOM_SCOMDETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_RANDOM_SCOMDET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_AVERAGE_SCOMDETcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_AVERAGE_SCOMDET(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_SR_MONOTONICcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_SR_MONOTONIC(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation cast backend verrou


static VG_REGPARM(3) Int vr_verrou_SR_SMONOTONICcast64FTo32F (Long a) {
  double *arg1 = (double*)(&a);
  float res;
  interflop_verrou_cast_double_to_float_SR_SMONOTONIC(*arg1, &res,backend_verrou_context);
  Int *d = (Int*)(&res);
  return *d;
}
#ifdef USE_VERROU_SQRT
// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrousqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrousqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrousqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrousqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrousqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrousqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend checkdenorm


static VG_REGPARM(0) void vr_checkdenormsqrt64F (void) {
  double res;
  interflop_checkdenorm_sqrt_double(arg1CopySSEDouble[0], &res, backend_checkdenorm_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_sqrt_double(arg1[0], res, backend_checkdenorm_context);
  interflop_checkdenorm_sqrt_double(arg1[1], res+1, backend_checkdenorm_context);
}

static VG_REGPARM(1) void vr_checkdenormsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_sqrt_double(arg1CopyAvxDouble[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormsqrt32F (void) {
  float res;
  interflop_checkdenorm_sqrt_float(arg1CopySSEFloat[0], &res, backend_checkdenorm_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_sqrt_float(arg1[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_sqrt_float(arg1[i], res+i, backend_checkdenorm_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verroucheck_float_maxsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double(arg1CopySSEDouble[0], &res, backend_verrou_context);
  interflop_check_float_max_sqrt_double(arg1CopySSEDouble[0], &res, backend_check_float_max_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double(arg1[0], res, backend_verrou_context);
  interflop_check_float_max_sqrt_double(arg1[0], res, backend_check_float_max_context);
  interflop_verrou_sqrt_double(arg1[1], res+1, backend_verrou_context);
  interflop_check_float_max_sqrt_double(arg1[1], res+1, backend_check_float_max_context);
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_check_float_max_sqrt_double(arg1CopyAvxDouble[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(0) void vr_verroucheck_float_maxsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float(arg1CopySSEFloat[0], &res, backend_verrou_context);
  interflop_check_float_max_sqrt_float(arg1CopySSEFloat[0], &res, backend_check_float_max_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float(arg1[i], res+i, backend_verrou_context);
     interflop_check_float_max_sqrt_float(arg1[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float(arg1[i], res+i, backend_verrou_context);
     interflop_check_float_max_sqrt_float(arg1[i], res+i, backend_check_float_max_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_NEARESTsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_NEAREST(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_NEAREST(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_NEAREST(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_NEARESTsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_NEAREST(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_NEARESTsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_NEAREST(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_NEAREST(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_NEARESTsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_NEAREST(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_UPWARDsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_UPWARD(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_UPWARD(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_UPWARD(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_UPWARDsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_UPWARD(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_UPWARDsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_UPWARD(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_UPWARD(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_UPWARDsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_UPWARD(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_DOWNWARDsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_DOWNWARD(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_DOWNWARD(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_DOWNWARD(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_DOWNWARD(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_DOWNWARDsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_DOWNWARD(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_DOWNWARD(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_DOWNWARD(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_FARTHESTsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_FARTHEST(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_FARTHEST(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_FARTHEST(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_FARTHEST(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_FARTHESTsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_FARTHEST(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_FARTHEST(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_FARTHEST(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_ZEROsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_ZERO(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_ZERO(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_ZERO(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_ZEROsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_ZERO(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_ZEROsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_ZERO(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_ZERO(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_ZEROsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_ZERO(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_AWAY_ZEROsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_AWAY_ZERO(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_AWAY_ZERO(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_AWAY_ZERO(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_AWAY_ZERO(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AWAY_ZEROsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_AWAY_ZERO(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_AWAY_ZERO(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_AWAY_ZERO(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_RANDOMsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_RANDOM(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_RANDOM(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_RANDOM(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOMsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_RANDOM(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOMsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_RANDOM(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_RANDOM(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOMsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_RANDOM(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_RANDOM_DETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_RANDOM_DET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_RANDOM_DET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_RANDOM_DET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_RANDOM_DET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_DETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_RANDOM_DET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_RANDOM_DET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_RANDOM_DET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_RANDOM_COMDETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_RANDOM_COMDET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_RANDOM_COMDET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_RANDOM_COMDET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_RANDOM_COMDET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_COMDETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_RANDOM_COMDET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_RANDOM_COMDET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_RANDOM_COMDET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_AVERAGEsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_AVERAGE(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_AVERAGE(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_AVERAGE(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_AVERAGE(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGEsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_AVERAGE(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_AVERAGE(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_AVERAGE(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_AVERAGE_DETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_AVERAGE_DET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_AVERAGE_DET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_AVERAGE_DET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_AVERAGE_DET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_DETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_AVERAGE_DET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_AVERAGE_DET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_AVERAGE_DET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_AVERAGE_COMDETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_AVERAGE_COMDET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_AVERAGE_COMDET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_AVERAGE_COMDET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_AVERAGE_COMDET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_COMDETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_AVERAGE_COMDET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_AVERAGE_COMDET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_AVERAGE_COMDET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_PRANDOMsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_PRANDOM(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_PRANDOM(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_PRANDOM(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_PRANDOM(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOMsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_PRANDOM(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_PRANDOM(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_PRANDOM(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_PRANDOM_DETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_PRANDOM_DET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_PRANDOM_DET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_PRANDOM_DET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_PRANDOM_DET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_DETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_PRANDOM_DET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_PRANDOM_DET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_PRANDOM_DET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_PRANDOM_COMDETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_PRANDOM_COMDET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_PRANDOM_COMDET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_PRANDOM_COMDET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_PRANDOM_COMDET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_COMDETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_PRANDOM_COMDET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_PRANDOM_COMDET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_PRANDOM_COMDET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_RANDOM_SCOMDETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_RANDOM_SCOMDET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_RANDOM_SCOMDET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_RANDOM_SCOMDET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_RANDOM_SCOMDET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_SCOMDETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_RANDOM_SCOMDET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_RANDOM_SCOMDET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_RANDOM_SCOMDET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_AVERAGE_SCOMDETsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_AVERAGE_SCOMDET(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_AVERAGE_SCOMDET(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_AVERAGE_SCOMDET(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_AVERAGE_SCOMDET(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_SCOMDETsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_AVERAGE_SCOMDET(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_AVERAGE_SCOMDET(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_AVERAGE_SCOMDET(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_SR_MONOTONICsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_SR_MONOTONIC(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_SR_MONOTONIC(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_SR_MONOTONIC(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_SR_MONOTONIC(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_MONOTONICsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_SR_MONOTONIC(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_SR_MONOTONIC(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_SR_MONOTONIC(arg1[i], res+i, backend_verrou_context);
  }
}


// generation of operation sqrt backend verrou


static VG_REGPARM(0) void vr_verrou_SR_SMONOTONICsqrt64F (void) {
  double res;
  interflop_verrou_sqrt_double_SR_SMONOTONIC(arg1CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsqrt64Fx2(/*OUT*/V128* output) {
  const double* arg1=arg1CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sqrt_double_SR_SMONOTONIC(arg1[0], res, backend_verrou_context);
  interflop_verrou_sqrt_double_SR_SMONOTONIC(arg1[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsqrt64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sqrt_double_SR_SMONOTONIC(arg1CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_SMONOTONICsqrt32F (void) {
  float res;
  interflop_verrou_sqrt_float_SR_SMONOTONIC(arg1CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsqrt32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sqrt_float_SR_SMONOTONIC(arg1[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsqrt32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sqrt_float_SR_SMONOTONIC(arg1[i], res+i, backend_verrou_context);
  }
}


#endif
// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrouadd64F (void){
  double res;
  interflop_verrou_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrouadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrouadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrouadd32F (void){
  float res;
  interflop_verrou_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrouadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrouadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrousub64F (void){
  double res;
  interflop_verrou_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrousub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrousub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrousub32F (void){
  float res;
  interflop_verrou_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrousub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrousub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verroumul64F (void){
  double res;
  interflop_verrou_mul_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroumul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verroumul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verroumul32F (void){
  float res;
  interflop_verrou_mul_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroumul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verroumul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verroudiv64F (void){
  double res;
  interflop_verrou_div_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroudiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verroudiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verroudiv32F (void){
  float res;
  interflop_verrou_div_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroudiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verroudiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


#ifdef USE_VERROU_QUAD
// generation of operation add backend mcaquad


static VG_REGPARM(0) void  vr_mcaquadadd64F (void){
  double res;
  interflop_mcaquad_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_mcaquad_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_mcaquad_add_double(arg1[0], arg2[0], res, backend_mcaquad_context);
  interflop_mcaquad_add_double(arg1[1], arg2[1], res+1, backend_mcaquad_context);
}

static VG_REGPARM(1) void vr_mcaquadadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_mcaquad_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(0) void vr_mcaquadadd32F (void){
  float res;
  interflop_mcaquad_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_mcaquad_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_mcaquad_add_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(1) void vr_mcaquadadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_mcaquad_add_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}


// generation of operation sub backend mcaquad


static VG_REGPARM(0) void  vr_mcaquadsub64F (void){
  double res;
  interflop_mcaquad_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_mcaquad_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_mcaquad_sub_double(arg1[0], arg2[0], res, backend_mcaquad_context);
  interflop_mcaquad_sub_double(arg1[1], arg2[1], res+1, backend_mcaquad_context);
}

static VG_REGPARM(1) void vr_mcaquadsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_mcaquad_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(0) void vr_mcaquadsub32F (void){
  float res;
  interflop_mcaquad_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_mcaquad_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_mcaquad_sub_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(1) void vr_mcaquadsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_mcaquad_sub_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}


// generation of operation mul backend mcaquad


static VG_REGPARM(0) void  vr_mcaquadmul64F (void){
  double res;
  interflop_mcaquad_mul_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_mcaquad_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_mcaquad_mul_double(arg1[0], arg2[0], res, backend_mcaquad_context);
  interflop_mcaquad_mul_double(arg1[1], arg2[1], res+1, backend_mcaquad_context);
}

static VG_REGPARM(1) void vr_mcaquadmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_mcaquad_mul_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(0) void vr_mcaquadmul32F (void){
  float res;
  interflop_mcaquad_mul_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_mcaquad_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_mcaquad_mul_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(1) void vr_mcaquadmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_mcaquad_mul_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}


// generation of operation div backend mcaquad


static VG_REGPARM(0) void  vr_mcaquaddiv64F (void){
  double res;
  interflop_mcaquad_div_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_mcaquad_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_mcaquaddiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_mcaquad_div_double(arg1[0], arg2[0], res, backend_mcaquad_context);
  interflop_mcaquad_div_double(arg1[1], arg2[1], res+1, backend_mcaquad_context);
}

static VG_REGPARM(1) void vr_mcaquaddiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_mcaquad_div_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(0) void vr_mcaquaddiv32F (void){
  float res;
  interflop_mcaquad_div_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_mcaquad_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_mcaquaddiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_mcaquad_div_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}

static VG_REGPARM(1) void vr_mcaquaddiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_mcaquad_div_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
  }
}


#endif //USE_VERROU_QUAD
// generation of operation add backend checkdenorm


static VG_REGPARM(0) void  vr_checkdenormadd64F (void){
  double res;
  interflop_checkdenorm_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkdenorm_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_add_double(arg1[0], arg2[0], res, backend_checkdenorm_context);
  interflop_checkdenorm_add_double(arg1[1], arg2[1], res+1, backend_checkdenorm_context);
}

static VG_REGPARM(1) void vr_checkdenormadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormadd32F (void){
  float res;
  interflop_checkdenorm_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkdenorm_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_add_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_add_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}


// generation of operation sub backend checkdenorm


static VG_REGPARM(0) void  vr_checkdenormsub64F (void){
  double res;
  interflop_checkdenorm_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkdenorm_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_sub_double(arg1[0], arg2[0], res, backend_checkdenorm_context);
  interflop_checkdenorm_sub_double(arg1[1], arg2[1], res+1, backend_checkdenorm_context);
}

static VG_REGPARM(1) void vr_checkdenormsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormsub32F (void){
  float res;
  interflop_checkdenorm_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkdenorm_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_sub_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_sub_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}


// generation of operation mul backend checkdenorm


static VG_REGPARM(0) void  vr_checkdenormmul64F (void){
  double res;
  interflop_checkdenorm_mul_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkdenorm_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_mul_double(arg1[0], arg2[0], res, backend_checkdenorm_context);
  interflop_checkdenorm_mul_double(arg1[1], arg2[1], res+1, backend_checkdenorm_context);
}

static VG_REGPARM(1) void vr_checkdenormmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_mul_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormmul32F (void){
  float res;
  interflop_checkdenorm_mul_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkdenorm_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_mul_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_mul_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}


// generation of operation div backend checkdenorm


static VG_REGPARM(0) void  vr_checkdenormdiv64F (void){
  double res;
  interflop_checkdenorm_div_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkdenorm_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_div_double(arg1[0], arg2[0], res, backend_checkdenorm_context);
  interflop_checkdenorm_div_double(arg1[1], arg2[1], res+1, backend_checkdenorm_context);
}

static VG_REGPARM(1) void vr_checkdenormdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_div_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormdiv32F (void){
  float res;
  interflop_checkdenorm_div_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkdenorm_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_div_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_div_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verroucheck_float_maxadd64F (void){
  double res;
  interflop_verrou_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  interflop_check_float_max_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_check_float_max_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_check_float_max_add_double(arg1[0], arg2[0], res, backend_check_float_max_context);
  interflop_verrou_add_double(arg1[1], arg2[1], res+1, backend_verrou_context);
  interflop_check_float_max_add_double(arg1[1], arg2[1], res+1, backend_check_float_max_context);
}

static VG_REGPARM(1) void vr_verroucheck_float_maxadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_check_float_max_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(0) void vr_verroucheck_float_maxadd32F (void){
  float res;
  interflop_verrou_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  interflop_check_float_max_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_check_float_max_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_add_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(1) void vr_verroucheck_float_maxadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_add_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verroucheck_float_maxsub64F (void){
  double res;
  interflop_verrou_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  interflop_check_float_max_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_check_float_max_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_check_float_max_sub_double(arg1[0], arg2[0], res, backend_check_float_max_context);
  interflop_verrou_sub_double(arg1[1], arg2[1], res+1, backend_verrou_context);
  interflop_check_float_max_sub_double(arg1[1], arg2[1], res+1, backend_check_float_max_context);
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_check_float_max_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(0) void vr_verroucheck_float_maxsub32F (void){
  float res;
  interflop_verrou_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  interflop_check_float_max_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_check_float_max_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_sub_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(1) void vr_verroucheck_float_maxsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_sub_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verroucheck_float_maxmul64F (void){
  double res;
  interflop_verrou_mul_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  interflop_check_float_max_mul_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_check_float_max_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_check_float_max_mul_double(arg1[0], arg2[0], res, backend_check_float_max_context);
  interflop_verrou_mul_double(arg1[1], arg2[1], res+1, backend_verrou_context);
  interflop_check_float_max_mul_double(arg1[1], arg2[1], res+1, backend_check_float_max_context);
}

static VG_REGPARM(1) void vr_verroucheck_float_maxmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_check_float_max_mul_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(0) void vr_verroucheck_float_maxmul32F (void){
  float res;
  interflop_verrou_mul_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  interflop_check_float_max_mul_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_check_float_max_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_mul_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(1) void vr_verroucheck_float_maxmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_mul_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verroucheck_float_maxdiv64F (void){
  double res;
  interflop_verrou_div_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  interflop_check_float_max_div_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_check_float_max_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_check_float_max_div_double(arg1[0], arg2[0], res, backend_check_float_max_context);
  interflop_verrou_div_double(arg1[1], arg2[1], res+1, backend_verrou_context);
  interflop_check_float_max_div_double(arg1[1], arg2[1], res+1, backend_check_float_max_context);
}

static VG_REGPARM(1) void vr_verroucheck_float_maxdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_check_float_max_div_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(0) void vr_verroucheck_float_maxdiv32F (void){
  float res;
  interflop_verrou_div_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  interflop_check_float_max_div_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_check_float_max_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheck_float_maxdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_div_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}

static VG_REGPARM(1) void vr_verroucheck_float_maxdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_check_float_max_div_float(arg1[i], arg2[i], res+i, backend_check_float_max_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_NEARESTadd64F (void){
  double res;
  interflop_verrou_add_double_NEAREST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_NEAREST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_NEAREST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_NEARESTadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_NEAREST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_NEARESTadd32F (void){
  float res;
  interflop_verrou_add_float_NEAREST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_NEARESTadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_UPWARDadd64F (void){
  double res;
  interflop_verrou_add_double_UPWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_UPWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_UPWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_UPWARDadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_UPWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_UPWARDadd32F (void){
  float res;
  interflop_verrou_add_float_UPWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_UPWARDadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_DOWNWARDadd64F (void){
  double res;
  interflop_verrou_add_double_DOWNWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_DOWNWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_DOWNWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_DOWNWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_DOWNWARDadd32F (void){
  float res;
  interflop_verrou_add_float_DOWNWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_FARTHESTadd64F (void){
  double res;
  interflop_verrou_add_double_FARTHEST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_FARTHEST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_FARTHEST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_FARTHESTadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_FARTHEST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_FARTHESTadd32F (void){
  float res;
  interflop_verrou_add_float_FARTHEST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_FARTHESTadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_ZEROadd64F (void){
  double res;
  interflop_verrou_add_double_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_ZEROadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_ZEROadd32F (void){
  float res;
  interflop_verrou_add_float_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_ZEROadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_AWAY_ZEROadd64F (void){
  double res;
  interflop_verrou_add_double_AWAY_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_AWAY_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_AWAY_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_AWAY_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AWAY_ZEROadd32F (void){
  float res;
  interflop_verrou_add_float_AWAY_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOMadd64F (void){
  double res;
  interflop_verrou_add_double_RANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_RANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_RANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOMadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_RANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOMadd32F (void){
  float res;
  interflop_verrou_add_float_RANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOMadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_DETadd64F (void){
  double res;
  interflop_verrou_add_double_RANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_RANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_RANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_RANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_DETadd32F (void){
  float res;
  interflop_verrou_add_float_RANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_COMDETadd64F (void){
  double res;
  interflop_verrou_add_double_RANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_RANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_RANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_RANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_COMDETadd32F (void){
  float res;
  interflop_verrou_add_float_RANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGEadd64F (void){
  double res;
  interflop_verrou_add_double_AVERAGE(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_AVERAGE(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_AVERAGE(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGEadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_AVERAGE(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGEadd32F (void){
  float res;
  interflop_verrou_add_float_AVERAGE(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGEadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_DETadd64F (void){
  double res;
  interflop_verrou_add_double_AVERAGE_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_AVERAGE_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_AVERAGE_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_AVERAGE_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_DETadd32F (void){
  float res;
  interflop_verrou_add_float_AVERAGE_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_COMDETadd64F (void){
  double res;
  interflop_verrou_add_double_AVERAGE_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_AVERAGE_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_AVERAGE_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_AVERAGE_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_COMDETadd32F (void){
  float res;
  interflop_verrou_add_float_AVERAGE_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOMadd64F (void){
  double res;
  interflop_verrou_add_double_PRANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_PRANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_PRANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOMadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_PRANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOMadd32F (void){
  float res;
  interflop_verrou_add_float_PRANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOMadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_DETadd64F (void){
  double res;
  interflop_verrou_add_double_PRANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_PRANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_PRANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_PRANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_DETadd32F (void){
  float res;
  interflop_verrou_add_float_PRANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_COMDETadd64F (void){
  double res;
  interflop_verrou_add_double_PRANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_PRANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_PRANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_PRANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_COMDETadd32F (void){
  float res;
  interflop_verrou_add_float_PRANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_SCOMDETadd64F (void){
  double res;
  interflop_verrou_add_double_RANDOM_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_RANDOM_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_RANDOM_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_RANDOM_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_SCOMDETadd32F (void){
  float res;
  interflop_verrou_add_float_RANDOM_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_SCOMDETadd64F (void){
  double res;
  interflop_verrou_add_double_AVERAGE_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_AVERAGE_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_AVERAGE_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_AVERAGE_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_SCOMDETadd32F (void){
  float res;
  interflop_verrou_add_float_AVERAGE_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_MONOTONICadd64F (void){
  double res;
  interflop_verrou_add_double_SR_MONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_SR_MONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_SR_MONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_SR_MONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_MONOTONICadd32F (void){
  float res;
  interflop_verrou_add_float_SR_MONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_SMONOTONICadd64F (void){
  double res;
  interflop_verrou_add_double_SR_SMONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double_SR_SMONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_add_double_SR_SMONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double_SR_SMONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_SMONOTONICadd32F (void){
  float res;
  interflop_verrou_add_float_SR_SMONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_NEARESTsub64F (void){
  double res;
  interflop_verrou_sub_double_NEAREST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_NEAREST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_NEAREST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_NEARESTsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_NEAREST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_NEARESTsub32F (void){
  float res;
  interflop_verrou_sub_float_NEAREST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_NEARESTsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_UPWARDsub64F (void){
  double res;
  interflop_verrou_sub_double_UPWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_UPWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_UPWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_UPWARDsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_UPWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_UPWARDsub32F (void){
  float res;
  interflop_verrou_sub_float_UPWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_UPWARDsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_DOWNWARDsub64F (void){
  double res;
  interflop_verrou_sub_double_DOWNWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_DOWNWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_DOWNWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_DOWNWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_DOWNWARDsub32F (void){
  float res;
  interflop_verrou_sub_float_DOWNWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_FARTHESTsub64F (void){
  double res;
  interflop_verrou_sub_double_FARTHEST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_FARTHEST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_FARTHEST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_FARTHEST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_FARTHESTsub32F (void){
  float res;
  interflop_verrou_sub_float_FARTHEST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_FARTHESTsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_ZEROsub64F (void){
  double res;
  interflop_verrou_sub_double_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_ZEROsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_ZEROsub32F (void){
  float res;
  interflop_verrou_sub_float_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_ZEROsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_AWAY_ZEROsub64F (void){
  double res;
  interflop_verrou_sub_double_AWAY_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_AWAY_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_AWAY_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_AWAY_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AWAY_ZEROsub32F (void){
  float res;
  interflop_verrou_sub_float_AWAY_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOMsub64F (void){
  double res;
  interflop_verrou_sub_double_RANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_RANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_RANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOMsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_RANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOMsub32F (void){
  float res;
  interflop_verrou_sub_float_RANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOMsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_DETsub64F (void){
  double res;
  interflop_verrou_sub_double_RANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_RANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_RANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_RANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_DETsub32F (void){
  float res;
  interflop_verrou_sub_float_RANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_COMDETsub64F (void){
  double res;
  interflop_verrou_sub_double_RANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_RANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_RANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_RANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_COMDETsub32F (void){
  float res;
  interflop_verrou_sub_float_RANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGEsub64F (void){
  double res;
  interflop_verrou_sub_double_AVERAGE(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_AVERAGE(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_AVERAGE(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_AVERAGE(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGEsub32F (void){
  float res;
  interflop_verrou_sub_float_AVERAGE(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGEsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_DETsub64F (void){
  double res;
  interflop_verrou_sub_double_AVERAGE_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_AVERAGE_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_AVERAGE_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_AVERAGE_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_DETsub32F (void){
  float res;
  interflop_verrou_sub_float_AVERAGE_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_COMDETsub64F (void){
  double res;
  interflop_verrou_sub_double_AVERAGE_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_AVERAGE_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_AVERAGE_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_AVERAGE_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_COMDETsub32F (void){
  float res;
  interflop_verrou_sub_float_AVERAGE_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOMsub64F (void){
  double res;
  interflop_verrou_sub_double_PRANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_PRANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_PRANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_PRANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOMsub32F (void){
  float res;
  interflop_verrou_sub_float_PRANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOMsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_DETsub64F (void){
  double res;
  interflop_verrou_sub_double_PRANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_PRANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_PRANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_PRANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_DETsub32F (void){
  float res;
  interflop_verrou_sub_float_PRANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_COMDETsub64F (void){
  double res;
  interflop_verrou_sub_double_PRANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_PRANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_PRANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_PRANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_COMDETsub32F (void){
  float res;
  interflop_verrou_sub_float_PRANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_SCOMDETsub64F (void){
  double res;
  interflop_verrou_sub_double_RANDOM_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_RANDOM_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_RANDOM_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_RANDOM_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_SCOMDETsub32F (void){
  float res;
  interflop_verrou_sub_float_RANDOM_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_SCOMDETsub64F (void){
  double res;
  interflop_verrou_sub_double_AVERAGE_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_AVERAGE_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_AVERAGE_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_AVERAGE_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_SCOMDETsub32F (void){
  float res;
  interflop_verrou_sub_float_AVERAGE_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_MONOTONICsub64F (void){
  double res;
  interflop_verrou_sub_double_SR_MONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_SR_MONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_SR_MONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_SR_MONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_MONOTONICsub32F (void){
  float res;
  interflop_verrou_sub_float_SR_MONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_SMONOTONICsub64F (void){
  double res;
  interflop_verrou_sub_double_SR_SMONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double_SR_SMONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_sub_double_SR_SMONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double_SR_SMONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_SMONOTONICsub32F (void){
  float res;
  interflop_verrou_sub_float_SR_SMONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_NEARESTmul64F (void){
  double res;
  interflop_verrou_mul_double_NEAREST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_NEAREST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_NEAREST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_NEARESTmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_NEAREST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_NEARESTmul32F (void){
  float res;
  interflop_verrou_mul_float_NEAREST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_NEARESTmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_UPWARDmul64F (void){
  double res;
  interflop_verrou_mul_double_UPWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_UPWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_UPWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_UPWARDmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_UPWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_UPWARDmul32F (void){
  float res;
  interflop_verrou_mul_float_UPWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_UPWARDmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_DOWNWARDmul64F (void){
  double res;
  interflop_verrou_mul_double_DOWNWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_DOWNWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_DOWNWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_DOWNWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_DOWNWARDmul32F (void){
  float res;
  interflop_verrou_mul_float_DOWNWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_FARTHESTmul64F (void){
  double res;
  interflop_verrou_mul_double_FARTHEST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_FARTHEST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_FARTHEST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_FARTHESTmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_FARTHEST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_FARTHESTmul32F (void){
  float res;
  interflop_verrou_mul_float_FARTHEST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_FARTHESTmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_ZEROmul64F (void){
  double res;
  interflop_verrou_mul_double_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_ZEROmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_ZEROmul32F (void){
  float res;
  interflop_verrou_mul_float_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_ZEROmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_AWAY_ZEROmul64F (void){
  double res;
  interflop_verrou_mul_double_AWAY_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_AWAY_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_AWAY_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_AWAY_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AWAY_ZEROmul32F (void){
  float res;
  interflop_verrou_mul_float_AWAY_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOMmul64F (void){
  double res;
  interflop_verrou_mul_double_RANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_RANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_RANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOMmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_RANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOMmul32F (void){
  float res;
  interflop_verrou_mul_float_RANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOMmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_DETmul64F (void){
  double res;
  interflop_verrou_mul_double_RANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_RANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_RANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_RANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_DETmul32F (void){
  float res;
  interflop_verrou_mul_float_RANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_COMDETmul64F (void){
  double res;
  interflop_verrou_mul_double_RANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_RANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_RANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_RANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_COMDETmul32F (void){
  float res;
  interflop_verrou_mul_float_RANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGEmul64F (void){
  double res;
  interflop_verrou_mul_double_AVERAGE(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_AVERAGE(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_AVERAGE(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGEmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_AVERAGE(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGEmul32F (void){
  float res;
  interflop_verrou_mul_float_AVERAGE(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGEmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_DETmul64F (void){
  double res;
  interflop_verrou_mul_double_AVERAGE_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_AVERAGE_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_AVERAGE_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_AVERAGE_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_DETmul32F (void){
  float res;
  interflop_verrou_mul_float_AVERAGE_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_COMDETmul64F (void){
  double res;
  interflop_verrou_mul_double_AVERAGE_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_AVERAGE_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_AVERAGE_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_AVERAGE_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_COMDETmul32F (void){
  float res;
  interflop_verrou_mul_float_AVERAGE_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOMmul64F (void){
  double res;
  interflop_verrou_mul_double_PRANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_PRANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_PRANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOMmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_PRANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOMmul32F (void){
  float res;
  interflop_verrou_mul_float_PRANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOMmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_DETmul64F (void){
  double res;
  interflop_verrou_mul_double_PRANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_PRANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_PRANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_PRANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_DETmul32F (void){
  float res;
  interflop_verrou_mul_float_PRANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_COMDETmul64F (void){
  double res;
  interflop_verrou_mul_double_PRANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_PRANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_PRANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_PRANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_COMDETmul32F (void){
  float res;
  interflop_verrou_mul_float_PRANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_SCOMDETmul64F (void){
  double res;
  interflop_verrou_mul_double_RANDOM_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_RANDOM_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_RANDOM_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_RANDOM_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_SCOMDETmul32F (void){
  float res;
  interflop_verrou_mul_float_RANDOM_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_SCOMDETmul64F (void){
  double res;
  interflop_verrou_mul_double_AVERAGE_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_AVERAGE_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_AVERAGE_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_AVERAGE_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_SCOMDETmul32F (void){
  float res;
  interflop_verrou_mul_float_AVERAGE_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_MONOTONICmul64F (void){
  double res;
  interflop_verrou_mul_double_SR_MONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_SR_MONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_SR_MONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_SR_MONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_MONOTONICmul32F (void){
  float res;
  interflop_verrou_mul_float_SR_MONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation mul backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_SMONOTONICmul64F (void){
  double res;
  interflop_verrou_mul_double_SR_SMONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICmul64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_mul_double_SR_SMONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_mul_double_SR_SMONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICmul64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_mul_double_SR_SMONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_SMONOTONICmul32F (void){
  float res;
  interflop_verrou_mul_float_SR_SMONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICmul32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_mul_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICmul32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_mul_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_NEARESTdiv64F (void){
  double res;
  interflop_verrou_div_double_NEAREST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_NEAREST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_NEAREST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_NEARESTdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_NEAREST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_NEARESTdiv32F (void){
  float res;
  interflop_verrou_div_float_NEAREST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_NEARESTdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_NEARESTdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_NEAREST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_UPWARDdiv64F (void){
  double res;
  interflop_verrou_div_double_UPWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_UPWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_UPWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_UPWARDdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_UPWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_UPWARDdiv32F (void){
  float res;
  interflop_verrou_div_float_UPWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_UPWARDdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_UPWARDdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_UPWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_DOWNWARDdiv64F (void){
  double res;
  interflop_verrou_div_double_DOWNWARD(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_DOWNWARD(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_DOWNWARD(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_DOWNWARD(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_DOWNWARDdiv32F (void){
  float res;
  interflop_verrou_div_float_DOWNWARD(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_DOWNWARDdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_DOWNWARD(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_FARTHESTdiv64F (void){
  double res;
  interflop_verrou_div_double_FARTHEST(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_FARTHEST(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_FARTHEST(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_FARTHESTdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_FARTHEST(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_FARTHESTdiv32F (void){
  float res;
  interflop_verrou_div_float_FARTHEST(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_FARTHESTdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_FARTHESTdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_FARTHEST(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_ZEROdiv64F (void){
  double res;
  interflop_verrou_div_double_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_ZEROdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_ZEROdiv32F (void){
  float res;
  interflop_verrou_div_float_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_ZEROdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_ZEROdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_AWAY_ZEROdiv64F (void){
  double res;
  interflop_verrou_div_double_AWAY_ZERO(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_AWAY_ZERO(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_AWAY_ZERO(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_AWAY_ZERO(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AWAY_ZEROdiv32F (void){
  float res;
  interflop_verrou_div_float_AWAY_ZERO(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AWAY_ZEROdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_AWAY_ZERO(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOMdiv64F (void){
  double res;
  interflop_verrou_div_double_RANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_RANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_RANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOMdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_RANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOMdiv32F (void){
  float res;
  interflop_verrou_div_float_RANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOMdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOMdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_RANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_DETdiv64F (void){
  double res;
  interflop_verrou_div_double_RANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_RANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_RANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_RANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_DETdiv32F (void){
  float res;
  interflop_verrou_div_float_RANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_DETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_RANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_COMDETdiv64F (void){
  double res;
  interflop_verrou_div_double_RANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_RANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_RANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_RANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_COMDETdiv32F (void){
  float res;
  interflop_verrou_div_float_RANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_COMDETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_RANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGEdiv64F (void){
  double res;
  interflop_verrou_div_double_AVERAGE(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_AVERAGE(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_AVERAGE(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGEdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_AVERAGE(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGEdiv32F (void){
  float res;
  interflop_verrou_div_float_AVERAGE(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGEdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGEdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_AVERAGE(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_DETdiv64F (void){
  double res;
  interflop_verrou_div_double_AVERAGE_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_AVERAGE_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_AVERAGE_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_AVERAGE_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_DETdiv32F (void){
  float res;
  interflop_verrou_div_float_AVERAGE_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_DETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_AVERAGE_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_COMDETdiv64F (void){
  double res;
  interflop_verrou_div_double_AVERAGE_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_AVERAGE_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_AVERAGE_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_AVERAGE_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_COMDETdiv32F (void){
  float res;
  interflop_verrou_div_float_AVERAGE_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_COMDETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_AVERAGE_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOMdiv64F (void){
  double res;
  interflop_verrou_div_double_PRANDOM(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_PRANDOM(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_PRANDOM(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOMdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_PRANDOM(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOMdiv32F (void){
  float res;
  interflop_verrou_div_float_PRANDOM(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOMdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOMdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_PRANDOM(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_DETdiv64F (void){
  double res;
  interflop_verrou_div_double_PRANDOM_DET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_PRANDOM_DET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_PRANDOM_DET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_PRANDOM_DET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_DETdiv32F (void){
  float res;
  interflop_verrou_div_float_PRANDOM_DET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_DETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_PRANDOM_DET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_PRANDOM_COMDETdiv64F (void){
  double res;
  interflop_verrou_div_double_PRANDOM_COMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_PRANDOM_COMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_PRANDOM_COMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_PRANDOM_COMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_PRANDOM_COMDETdiv32F (void){
  float res;
  interflop_verrou_div_float_PRANDOM_COMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_PRANDOM_COMDETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_PRANDOM_COMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_RANDOM_SCOMDETdiv64F (void){
  double res;
  interflop_verrou_div_double_RANDOM_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_RANDOM_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_RANDOM_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_RANDOM_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_RANDOM_SCOMDETdiv32F (void){
  float res;
  interflop_verrou_div_float_RANDOM_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_RANDOM_SCOMDETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_RANDOM_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_AVERAGE_SCOMDETdiv64F (void){
  double res;
  interflop_verrou_div_double_AVERAGE_SCOMDET(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_AVERAGE_SCOMDET(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_AVERAGE_SCOMDET(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_AVERAGE_SCOMDET(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_AVERAGE_SCOMDETdiv32F (void){
  float res;
  interflop_verrou_div_float_AVERAGE_SCOMDET(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_AVERAGE_SCOMDETdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_AVERAGE_SCOMDET(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_MONOTONICdiv64F (void){
  double res;
  interflop_verrou_div_double_SR_MONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_SR_MONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_SR_MONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_SR_MONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_MONOTONICdiv32F (void){
  float res;
  interflop_verrou_div_float_SR_MONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_MONOTONICdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_SR_MONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation div backend verrou


static VG_REGPARM(0) void  vr_verrou_SR_SMONOTONICdiv64F (void){
  double res;
  interflop_verrou_div_double_SR_SMONOTONIC(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICdiv64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_div_double_SR_SMONOTONIC(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_verrou_div_double_SR_SMONOTONIC(arg1[1], arg2[1], res+1, backend_verrou_context);
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICdiv64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_div_double_SR_SMONOTONIC(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(0) void vr_verrou_SR_SMONOTONICdiv32F (void){
  float res;
  interflop_verrou_div_float_SR_SMONOTONIC(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICdiv32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_div_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}

static VG_REGPARM(1) void vr_verrou_SR_SMONOTONICdiv32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_div_float_SR_SMONOTONIC(arg1[i], arg2[i], res+i, backend_verrou_context);
  }
}


// generation of operation add backend verrou


static VG_REGPARM(0) void  vr_verroucheckcancellationadd64F (void){
  double res;
  interflop_verrou_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  interflop_checkcancellation_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkcancellation_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheckcancellationadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_add_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_checkcancellation_add_double(arg1[0], arg2[0], res, backend_checkcancellation_context);
  interflop_verrou_add_double(arg1[1], arg2[1], res+1, backend_verrou_context);
  interflop_checkcancellation_add_double(arg1[1], arg2[1], res+1, backend_checkcancellation_context);
}

static VG_REGPARM(1) void vr_verroucheckcancellationadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_checkcancellation_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(0) void vr_verroucheckcancellationadd32F (void){
  float res;
  interflop_verrou_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  interflop_checkcancellation_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkcancellation_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheckcancellationadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_add_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_checkcancellation_add_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(1) void vr_verroucheckcancellationadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_add_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_checkcancellation_add_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}


// generation of operation sub backend verrou


static VG_REGPARM(0) void  vr_verroucheckcancellationsub64F (void){
  double res;
  interflop_verrou_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_verrou_context);
  interflop_checkcancellation_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkcancellation_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_verroucheckcancellationsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_verrou_sub_double(arg1[0], arg2[0], res, backend_verrou_context);
  interflop_checkcancellation_sub_double(arg1[0], arg2[0], res, backend_checkcancellation_context);
  interflop_verrou_sub_double(arg1[1], arg2[1], res+1, backend_verrou_context);
  interflop_checkcancellation_sub_double(arg1[1], arg2[1], res+1, backend_checkcancellation_context);
}

static VG_REGPARM(1) void vr_verroucheckcancellationsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_verrou_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_verrou_context);
     interflop_checkcancellation_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(0) void vr_verroucheckcancellationsub32F (void){
  float res;
  interflop_verrou_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_verrou_context);
  interflop_checkcancellation_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkcancellation_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_verroucheckcancellationsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_verrou_sub_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_checkcancellation_sub_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(1) void vr_verroucheckcancellationsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_verrou_sub_float(arg1[i], arg2[i], res+i, backend_verrou_context);
     interflop_checkcancellation_sub_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}


#ifdef USE_VERROU_QUAD
// generation of operation add backend mcaquad


static VG_REGPARM(0) void  vr_mcaquadcheckcancellationadd64F (void){
  double res;
  interflop_mcaquad_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_mcaquad_context);
  interflop_checkcancellation_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkcancellation_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_mcaquad_add_double(arg1[0], arg2[0], res, backend_mcaquad_context);
  interflop_checkcancellation_add_double(arg1[0], arg2[0], res, backend_checkcancellation_context);
  interflop_mcaquad_add_double(arg1[1], arg2[1], res+1, backend_mcaquad_context);
  interflop_checkcancellation_add_double(arg1[1], arg2[1], res+1, backend_checkcancellation_context);
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_mcaquad_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_mcaquad_context);
     interflop_checkcancellation_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(0) void vr_mcaquadcheckcancellationadd32F (void){
  float res;
  interflop_mcaquad_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_mcaquad_context);
  interflop_checkcancellation_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkcancellation_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_mcaquad_add_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
     interflop_checkcancellation_add_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_mcaquad_add_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
     interflop_checkcancellation_add_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}


// generation of operation sub backend mcaquad


static VG_REGPARM(0) void  vr_mcaquadcheckcancellationsub64F (void){
  double res;
  interflop_mcaquad_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_mcaquad_context);
  interflop_checkcancellation_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkcancellation_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_mcaquad_sub_double(arg1[0], arg2[0], res, backend_mcaquad_context);
  interflop_checkcancellation_sub_double(arg1[0], arg2[0], res, backend_checkcancellation_context);
  interflop_mcaquad_sub_double(arg1[1], arg2[1], res+1, backend_mcaquad_context);
  interflop_checkcancellation_sub_double(arg1[1], arg2[1], res+1, backend_checkcancellation_context);
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_mcaquad_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_mcaquad_context);
     interflop_checkcancellation_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(0) void vr_mcaquadcheckcancellationsub32F (void){
  float res;
  interflop_mcaquad_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_mcaquad_context);
  interflop_checkcancellation_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkcancellation_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_mcaquad_sub_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
     interflop_checkcancellation_sub_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(1) void vr_mcaquadcheckcancellationsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_mcaquad_sub_float(arg1[i], arg2[i], res+i, backend_mcaquad_context);
     interflop_checkcancellation_sub_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}


#endif //USE_VERROU_QUAD
// generation of operation add backend checkdenorm


static VG_REGPARM(0) void  vr_checkdenormcheckcancellationadd64F (void){
  double res;
  interflop_checkdenorm_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkdenorm_context);
  interflop_checkcancellation_add_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkcancellation_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationadd64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_add_double(arg1[0], arg2[0], res, backend_checkdenorm_context);
  interflop_checkcancellation_add_double(arg1[0], arg2[0], res, backend_checkcancellation_context);
  interflop_checkdenorm_add_double(arg1[1], arg2[1], res+1, backend_checkdenorm_context);
  interflop_checkcancellation_add_double(arg1[1], arg2[1], res+1, backend_checkcancellation_context);
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationadd64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkdenorm_context);
     interflop_checkcancellation_add_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormcheckcancellationadd32F (void){
  float res;
  interflop_checkdenorm_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkdenorm_context);
  interflop_checkcancellation_add_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkcancellation_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationadd32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_add_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
     interflop_checkcancellation_add_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationadd32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_add_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
     interflop_checkcancellation_add_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}


// generation of operation sub backend checkdenorm


static VG_REGPARM(0) void  vr_checkdenormcheckcancellationsub64F (void){
  double res;
  interflop_checkdenorm_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkdenorm_context);
  interflop_checkcancellation_sub_double(arg1CopySSEDouble[0], arg2CopySSEDouble[0], &res, backend_checkcancellation_context);
  arg1CopySSEDouble[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationsub64Fx2(/*OUT*/V128* output){
  const double* arg1=arg1CopySSEDouble;
  const double* arg2=arg2CopySSEDouble;
  double* res=(double*) output;
  interflop_checkdenorm_sub_double(arg1[0], arg2[0], res, backend_checkdenorm_context);
  interflop_checkcancellation_sub_double(arg1[0], arg2[0], res, backend_checkcancellation_context);
  interflop_checkdenorm_sub_double(arg1[1], arg2[1], res+1, backend_checkdenorm_context);
  interflop_checkcancellation_sub_double(arg1[1], arg2[1], res+1, backend_checkcancellation_context);
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationsub64Fx4 (/*OUT*/V256* output){
  double* res=(double*) output;
  for(int i=0; i<4; i++){
     interflop_checkdenorm_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkdenorm_context);
     interflop_checkcancellation_sub_double(arg1CopyAvxDouble[i], arg2CopyAvxDouble[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(0) void vr_checkdenormcheckcancellationsub32F (void){
  float res;
  interflop_checkdenorm_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkdenorm_context);
  interflop_checkcancellation_sub_float(arg1CopySSEFloat[0], arg2CopySSEFloat[0], &res, backend_checkcancellation_context);
  arg1CopySSEFloat[0]=res;
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationsub32Fx8 (/*OUT*/V256* output){
  float* res=(float*) output;
  float* arg1=arg1CopyAvxFloat;
  float* arg2=arg2CopyAvxFloat;
  for(int i=0; i<8; i++){
     interflop_checkdenorm_sub_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
     interflop_checkcancellation_sub_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}

static VG_REGPARM(1) void vr_checkdenormcheckcancellationsub32Fx4 (/*OUT*/V128* output){
  float* res=(float*) output;

  const float* arg1=arg1CopySSEFloat;
  const float* arg2=arg2CopySSEFloat;
  for(int i=0; i<4;i++){
     interflop_checkdenorm_sub_float(arg1[i], arg2[i], res+i, backend_checkdenorm_context);
     interflop_checkcancellation_sub_float(arg1[i], arg2[i], res+i, backend_checkcancellation_context);
  }
}


// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verroumadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verroumadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verroumsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verroumsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
#ifdef USE_VERROU_QUAD
// generation of operation madd backend mcaquad
//FMA Operator
static VG_REGPARM(3) Long vr_mcaquadmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_mcaquad_madd_double(*arg1, *arg2,  *arg3, &res, backend_mcaquad_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_mcaquadmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_mcaquad_madd_float(*arg1, *arg2,  *arg3, &res, backend_mcaquad_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend mcaquad
//FMA Operator
static VG_REGPARM(3) Long vr_mcaquadmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_mcaquad_madd_double(*arg1, *arg2, - *arg3, &res, backend_mcaquad_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_mcaquadmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_mcaquad_madd_float(*arg1, *arg2, - *arg3, &res, backend_mcaquad_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
#endif //USE_VERROU_QUAD
// generation of operation madd backend checkdenorm
//FMA Operator
static VG_REGPARM(3) Long vr_checkdenormmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_checkdenorm_madd_double(*arg1, *arg2,  *arg3, &res, backend_checkdenorm_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_checkdenormmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_checkdenorm_madd_float(*arg1, *arg2,  *arg3, &res, backend_checkdenorm_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend checkdenorm
//FMA Operator
static VG_REGPARM(3) Long vr_checkdenormmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_checkdenorm_madd_double(*arg1, *arg2, - *arg3, &res, backend_checkdenorm_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_checkdenormmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_checkdenorm_madd_float(*arg1, *arg2, - *arg3, &res, backend_checkdenorm_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verroucheckcancellationmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
  interflop_checkcancellation_madd_double(*arg1, *arg2,  *arg3, &res, backend_checkcancellation_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verroucheckcancellationmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
  interflop_checkcancellation_madd_float(*arg1, *arg2,  *arg3, &res, backend_checkcancellation_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verroucheckcancellationmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
  interflop_checkcancellation_madd_double(*arg1, *arg2, - *arg3, &res, backend_checkcancellation_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verroucheckcancellationmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
  interflop_checkcancellation_madd_float(*arg1, *arg2, - *arg3, &res, backend_checkcancellation_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
#ifdef USE_VERROU_QUAD
// generation of operation madd backend mcaquad
//FMA Operator
static VG_REGPARM(3) Long vr_mcaquadcheckcancellationmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_mcaquad_madd_double(*arg1, *arg2,  *arg3, &res, backend_mcaquad_context);
  interflop_checkcancellation_madd_double(*arg1, *arg2,  *arg3, &res, backend_checkcancellation_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_mcaquadcheckcancellationmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_mcaquad_madd_float(*arg1, *arg2,  *arg3, &res, backend_mcaquad_context);
  interflop_checkcancellation_madd_float(*arg1, *arg2,  *arg3, &res, backend_checkcancellation_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend mcaquad
//FMA Operator
static VG_REGPARM(3) Long vr_mcaquadcheckcancellationmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_mcaquad_madd_double(*arg1, *arg2, - *arg3, &res, backend_mcaquad_context);
  interflop_checkcancellation_madd_double(*arg1, *arg2, - *arg3, &res, backend_checkcancellation_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_mcaquadcheckcancellationmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_mcaquad_madd_float(*arg1, *arg2, - *arg3, &res, backend_mcaquad_context);
  interflop_checkcancellation_madd_float(*arg1, *arg2, - *arg3, &res, backend_checkcancellation_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
#endif //USE_VERROU_QUAD
// generation of operation madd backend checkdenorm
//FMA Operator
static VG_REGPARM(3) Long vr_checkdenormcheckcancellationmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_checkdenorm_madd_double(*arg1, *arg2,  *arg3, &res, backend_checkdenorm_context);
  interflop_checkcancellation_madd_double(*arg1, *arg2,  *arg3, &res, backend_checkcancellation_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_checkdenormcheckcancellationmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_checkdenorm_madd_float(*arg1, *arg2,  *arg3, &res, backend_checkdenorm_context);
  interflop_checkcancellation_madd_float(*arg1, *arg2,  *arg3, &res, backend_checkcancellation_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend checkdenorm
//FMA Operator
static VG_REGPARM(3) Long vr_checkdenormcheckcancellationmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_checkdenorm_madd_double(*arg1, *arg2, - *arg3, &res, backend_checkdenorm_context);
  interflop_checkcancellation_madd_double(*arg1, *arg2, - *arg3, &res, backend_checkcancellation_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_checkdenormcheckcancellationmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_checkdenorm_madd_float(*arg1, *arg2, - *arg3, &res, backend_checkdenorm_context);
  interflop_checkcancellation_madd_float(*arg1, *arg2, - *arg3, &res, backend_checkcancellation_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verroucheck_float_maxmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
  interflop_check_float_max_madd_double(*arg1, *arg2,  *arg3, &res, backend_check_float_max_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verroucheck_float_maxmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
  interflop_check_float_max_madd_float(*arg1, *arg2,  *arg3, &res, backend_check_float_max_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verroucheck_float_maxmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
  interflop_check_float_max_madd_double(*arg1, *arg2, - *arg3, &res, backend_check_float_max_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verroucheck_float_maxmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
  interflop_check_float_max_madd_float(*arg1, *arg2, - *arg3, &res, backend_check_float_max_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_NEARESTmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_NEAREST(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_NEARESTmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_NEAREST(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_UPWARDmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_UPWARD(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_UPWARDmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_UPWARD(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_DOWNWARDmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_DOWNWARD(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_DOWNWARDmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_DOWNWARD(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_FARTHESTmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_FARTHEST(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_FARTHESTmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_FARTHEST(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_ZEROmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_ZERO(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_ZEROmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_ZERO(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AWAY_ZEROmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AWAY_ZERO(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AWAY_ZEROmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AWAY_ZERO(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOMmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOMmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOM_DETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM_DET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOM_DETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM_DET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOM_COMDETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM_COMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOM_COMDETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM_COMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGEmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGEmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGE_DETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE_DET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGE_DETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE_DET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGE_COMDETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE_COMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGE_COMDETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE_COMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_PRANDOMmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_PRANDOM(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_PRANDOMmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_PRANDOM(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_PRANDOM_DETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_PRANDOM_DET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_PRANDOM_DETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_PRANDOM_DET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_PRANDOM_COMDETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_PRANDOM_COMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_PRANDOM_COMDETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_PRANDOM_COMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOM_SCOMDETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM_SCOMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOM_SCOMDETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM_SCOMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGE_SCOMDETmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE_SCOMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGE_SCOMDETmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE_SCOMDET(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_SR_MONOTONICmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_SR_MONOTONIC(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_SR_MONOTONICmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_SR_MONOTONIC(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation madd backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_SR_SMONOTONICmadd64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_SR_SMONOTONIC(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_SR_SMONOTONICmadd32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_SR_SMONOTONIC(*arg1, *arg2,  *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_NEARESTmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_NEAREST(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_NEARESTmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_NEAREST(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_UPWARDmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_UPWARD(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_UPWARDmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_UPWARD(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_DOWNWARDmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_DOWNWARD(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_DOWNWARDmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_DOWNWARD(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_FARTHESTmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_FARTHEST(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_FARTHESTmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_FARTHEST(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_ZEROmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_ZERO(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_ZEROmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_ZERO(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AWAY_ZEROmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AWAY_ZERO(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AWAY_ZEROmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AWAY_ZERO(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOMmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOMmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOM_DETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM_DET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOM_DETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM_DET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOM_COMDETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM_COMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOM_COMDETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM_COMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGEmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGEmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGE_DETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE_DET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGE_DETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE_DET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGE_COMDETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE_COMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGE_COMDETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE_COMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_PRANDOMmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_PRANDOM(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_PRANDOMmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_PRANDOM(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_PRANDOM_DETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_PRANDOM_DET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_PRANDOM_DETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_PRANDOM_DET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_PRANDOM_COMDETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_PRANDOM_COMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_PRANDOM_COMDETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_PRANDOM_COMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_RANDOM_SCOMDETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_RANDOM_SCOMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_RANDOM_SCOMDETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_RANDOM_SCOMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_AVERAGE_SCOMDETmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_AVERAGE_SCOMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_AVERAGE_SCOMDETmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_AVERAGE_SCOMDET(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_SR_MONOTONICmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_SR_MONOTONIC(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_SR_MONOTONICmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_SR_MONOTONIC(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
// generation of operation msub backend verrou
//FMA Operator
static VG_REGPARM(3) Long vr_verrou_SR_SMONOTONICmsub64F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  double *arg1 = (double*)(&a);
  double *arg2 = (double*)(&b);
  double *arg3 = (double*)(&c);
  double res;
  interflop_verrou_madd_double_SR_SMONOTONIC(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  double res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Long *d = (Long*)(&res);
  return *d;
}

static VG_REGPARM(3) Int vr_verrou_SR_SMONOTONICmsub32F (Long a, Long b, Long c) {
#ifdef USE_VERROU_FMA
  float *arg1 = (float*)(&a);
  float *arg2 = (float*)(&b);
  float *arg3 = (float*)(&c);
  float res;
  interflop_verrou_madd_float_SR_SMONOTONIC(*arg1, *arg2, - *arg3, &res, backend_verrou_context);
#else
  float res=0.;
  VG_(tool_panic) ( "Verrou needs to be compiled with FMA support \n");
#endif
  Int *d = (Int*)(&res);
  return *d;
}
